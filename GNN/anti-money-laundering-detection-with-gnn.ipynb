{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Money Laundering Detection with GNN node classification\n",
    "### This notenook includes GNN model training and dataset implementation with PyG library. In this example, we used LI-Small_Trans.csv as our dataset for training and testing.  \n",
    "### For more details, please view https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-07T05:03:44.040372Z",
     "iopub.status.busy": "2023-10-07T05:03:44.039793Z",
     "iopub.status.idle": "2023-10-07T05:03:58.147392Z",
     "shell.execute_reply": "2023-10-07T05:03:58.146038Z",
     "shell.execute_reply.started": "2023-10-07T05:03:44.040343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = './data/raw/LI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and possible feature engineering\n",
    "Let's look into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:33:22.849494Z",
     "iopub.status.busy": "2023-10-07T05:33:22.849049Z",
     "iopub.status.idle": "2023-10-07T05:33:22.867501Z",
     "shell.execute_reply": "2023-10-07T05:33:22.866198Z",
     "shell.execute_reply.started": "2023-10-07T05:33:22.849448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "0  2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
      "1  2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
      "2  2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
      "3  2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
      "4  2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
      "\n",
      "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "0       3195403.00          US Dollar   3195403.00        US Dollar   \n",
      "1          1858.96          US Dollar      1858.96        US Dollar   \n",
      "2        592571.00          US Dollar    592571.00        US Dollar   \n",
      "3            12.32          US Dollar        12.32        US Dollar   \n",
      "4          2941.56          US Dollar      2941.56        US Dollar   \n",
      "\n",
      "  Payment Format  Is Laundering  \n",
      "0   Reinvestment              0  \n",
      "1   Reinvestment              0  \n",
      "2         Cheque              0  \n",
      "3   Reinvestment              0  \n",
      "4   Reinvestment              0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the viewing the dataframe, we suggest that we can extract all accounts from receiver and payer among all transcation for sorting the suspicious accounts. We can transform the whole dataset into node classification problem by considering accounts as nodes while transcation as edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object columns should be encoded into classes with sklearn LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:36:52.790986Z",
     "iopub.status.busy": "2023-10-07T05:36:52.790429Z",
     "iopub.status.idle": "2023-10-07T05:36:52.797831Z",
     "shell.execute_reply": "2023-10-07T05:36:52.796721Z",
     "shell.execute_reply.started": "2023-10-07T05:36:52.790952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp              object\n",
      "From Bank               int64\n",
      "Account                object\n",
      "To Bank                 int64\n",
      "Account.1              object\n",
      "Amount Received       float64\n",
      "Receiving Currency     object\n",
      "Amount Paid           float64\n",
      "Payment Currency       object\n",
      "Payment Format         object\n",
      "Is Laundering           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:40:11.526713Z",
     "iopub.status.busy": "2023-10-07T05:40:11.526397Z",
     "iopub.status.idle": "2023-10-07T05:40:12.913554Z",
     "shell.execute_reply": "2023-10-07T05:40:12.912335Z",
     "shell.execute_reply.started": "2023-10-07T05:40:11.526687Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp             0\n",
      "From Bank             0\n",
      "Account               0\n",
      "To Bank               0\n",
      "Account.1             0\n",
      "Amount Received       0\n",
      "Receiving Currency    0\n",
      "Amount Paid           0\n",
      "Payment Currency      0\n",
      "Payment Format        0\n",
      "Is Laundering         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns representing paid and received amount of each transcation, wondering if it is necessary to split the amount into two columns when they shared the same value, unless there are transcation fee/transcation between different currency. Let's find out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:45:40.568327Z",
     "iopub.status.busy": "2023-10-07T05:45:40.567898Z",
     "iopub.status.idle": "2023-10-07T05:45:40.594713Z",
     "shell.execute_reply": "2023-10-07T05:45:40.593358Z",
     "shell.execute_reply.started": "2023-10-07T05:45:40.568296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Received equals to Amount Paid:\n",
      "False\n",
      "Receiving Currency equals to Payment Currency:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Amount Received equals to Amount Paid:')\n",
    "print(df['Amount Received'].equals(df['Amount Paid']))\n",
    "print('Receiving Currency equals to Payment Currency:')\n",
    "print(df['Receiving Currency'].equals(df['Payment Currency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seens involved the transcations between different currency, let's print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:46:16.614934Z",
     "iopub.status.busy": "2023-10-07T05:46:16.614531Z",
     "iopub.status.idle": "2023-10-07T05:46:17.289425Z",
     "shell.execute_reply": "2023-10-07T05:46:17.288314Z",
     "shell.execute_reply.started": "2023-10-07T05:46:16.614907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98858 rows x 11 columns]\n",
      "---------------------------------------------------------------------------\n",
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98876 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
    "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
    "print(not_equal1)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(not_equal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of two df shows that there are transcation fee and transcation between different currency, we cannot combine/drop the amount columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to encode the columns, we have to make sure that the classes of same attribute are aligned.\n",
    "Let's check if the list of Receiving Currency and Payment Currency are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:51:06.994519Z",
     "iopub.status.busy": "2023-10-07T05:51:06.994058Z",
     "iopub.status.idle": "2023-10-07T05:51:07.455980Z",
     "shell.execute_reply": "2023-10-07T05:51:07.454722Z",
     "shell.execute_reply.started": "2023-10-07T05:51:06.994490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df['Receiving Currency'].unique()))\n",
    "print(sorted(df['Payment Currency'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### We will show the functions used in the PyG dataset first, dataset and model training will be provided in bottom section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data preprocessing, we perform below transformation:  \n",
    "1. Transform the Timestamp with min max normalization.  \n",
    "2. Create unique ID for each account by adding bank code with account number.  \n",
    "3. Create receiving_df with the information of receiving accounts, received amount and currency\n",
    "4. Create paying_df with the information of payer accounts, paid amount and currency\n",
    "5. Create a list of currency used among all transactions\n",
    "6. Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:11.423289Z",
     "iopub.status.busy": "2023-10-07T05:53:11.422843Z",
     "iopub.status.idle": "2023-10-07T05:53:11.432504Z",
     "shell.execute_reply": "2023-10-07T05:53:11.431355Z",
     "shell.execute_reply.started": "2023-10-07T05:53:11.423245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def df_label_encoder(df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "def preprocess(df):\n",
    "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look of processed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:15.266963Z",
     "iopub.status.busy": "2023-10-07T05:53:15.266592Z",
     "iopub.status.idle": "2023-10-07T05:53:56.218064Z",
     "shell.execute_reply": "2023-10-07T05:53:56.216975Z",
     "shell.execute_reply.started": "2023-10-07T05:53:15.266935Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  From Bank      Account  To Bank        Account.1  \\\n",
      "3408783   0.266147          0  0_800060CE0    11314  11314_800990320   \n",
      "3986981   0.318925          0  0_800060CE0    11314  11314_800990320   \n",
      "4804475   0.393400          0  0_800060CE0    11314  11314_800990320   \n",
      "4804474   0.394151          0  0_800060CE0    11314  11314_800990320   \n",
      "6690464   0.547730          0  0_800060CE0     1390   1390_800E49870   \n",
      "\n",
      "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
      "3408783          8081.58                   4      8081.58                 4   \n",
      "3986981         47468.31                   4     47468.31                 4   \n",
      "4804475          8081.58                   4      8081.58                 4   \n",
      "4804474         47468.31                   4     47468.31                 4   \n",
      "6690464           787.72                   4       787.72                 4   \n",
      "\n",
      "         Payment Format  Is Laundering  \n",
      "3408783               4              0  \n",
      "3986981               3              0  \n",
      "4804475               4              0  \n",
      "4804474               3              0  \n",
      "6690464               3              0  \n"
     ]
    }
   ],
   "source": [
    "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paying df and receiving df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:25.918744Z",
     "iopub.status.busy": "2023-10-07T05:57:25.918280Z",
     "iopub.status.idle": "2023-10-07T05:57:25.929797Z",
     "shell.execute_reply": "2023-10-07T05:57:25.928625Z",
     "shell.execute_reply.started": "2023-10-07T05:57:25.918708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Account  Amount Received  Receiving Currency\n",
      "3408783  11314_800990320          8081.58                   4\n",
      "3986981  11314_800990320         47468.31                   4\n",
      "4804475  11314_800990320          8081.58                   4\n",
      "4804474  11314_800990320         47468.31                   4\n",
      "6690464   1390_800E49870           787.72                   4\n",
      "             Account  Amount Paid  Payment Currency\n",
      "3408783  0_800060CE0      8081.58                 4\n",
      "3986981  0_800060CE0     47468.31                 4\n",
      "4804475  0_800060CE0      8081.58                 4\n",
      "4804474  0_800060CE0     47468.31                 4\n",
      "6690464  0_800060CE0       787.72                 4\n"
     ]
    }
   ],
   "source": [
    "print(receiving_df.head())\n",
    "print(paying_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currency_ls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:28.907031Z",
     "iopub.status.busy": "2023-10-07T05:57:28.906667Z",
     "iopub.status.idle": "2023-10-07T05:57:28.913761Z",
     "shell.execute_reply": "2023-10-07T05:57:28.912327Z",
     "shell.execute_reply.started": "2023-10-07T05:57:28.907004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14)]\n"
     ]
    }
   ],
   "source": [
    "print(currency_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.  \n",
    "In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with 'Is Laundering' == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:31.850839Z",
     "iopub.status.busy": "2023-10-07T05:57:31.850459Z",
     "iopub.status.idle": "2023-10-07T05:57:31.858990Z",
     "shell.execute_reply": "2023-10-07T05:57:31.857826Z",
     "shell.execute_reply.started": "2023-10-07T05:57:31.850810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_all_account(df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look of the account list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:34.379521Z",
     "iopub.status.busy": "2023-10-07T05:57:34.378456Z",
     "iopub.status.idle": "2023-10-07T05:57:41.317058Z",
     "shell.execute_reply": "2023-10-07T05:57:41.316062Z",
     "shell.execute_reply.started": "2023-10-07T05:57:34.379481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Account  Bank  Is Laundering\n",
      "0  0_800060CE0     0              0\n",
      "1  0_800061260     0              0\n",
      "2  0_800062D90     0              0\n",
      "3  0_800062F80     0              0\n",
      "4  0_800064980     0              0\n"
     ]
    }
   ],
   "source": [
    "accounts = get_all_account(df)\n",
    "print(accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node features\n",
    "For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:43.694369Z",
     "iopub.status.busy": "2023-10-07T05:57:43.693958Z",
     "iopub.status.idle": "2023-10-07T05:57:43.701141Z",
     "shell.execute_reply": "2023-10-07T05:57:43.699901Z",
     "shell.execute_reply.started": "2023-10-07T05:57:43.694334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
    "    for i in currency_ls:\n",
    "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "    accounts = accounts.fillna(0)\n",
    "    return accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:45.915808Z",
     "iopub.status.busy": "2023-10-07T05:57:45.915112Z",
     "iopub.status.idle": "2023-10-07T05:57:45.926442Z",
     "shell.execute_reply": "2023-10-07T05:57:45.924963Z",
     "shell.execute_reply.started": "2023-10-07T05:57:45.915734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = df_label_encoder(node_df,['Bank'])\n",
    "#         node_df = torch.from_numpy(node_df.values).to(torch.float)  # comment for visualization\n",
    "        return node_df, node_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look of node_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:48.258031Z",
     "iopub.status.busy": "2023-10-07T05:57:48.257639Z",
     "iopub.status.idle": "2023-10-07T05:57:56.275657Z",
     "shell.execute_reply": "2023-10-07T05:57:56.274417Z",
     "shell.execute_reply.started": "2023-10-07T05:57:48.257999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
      "0     0         0.0         0.0         0.0         0.0         0.0   \n",
      "1     0         0.0         0.0         0.0         0.0         0.0   \n",
      "2     0         0.0         0.0         0.0         0.0         0.0   \n",
      "3     0         0.0         0.0         0.0         0.0         0.0   \n",
      "4     0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "\n",
      "   avg paid 11    avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
      "0          0.0  307628.336486          0.0          0.0             0.0   \n",
      "1          0.0    1858.960000          0.0          0.0             0.0   \n",
      "2          0.0  307628.336486          0.0          0.0             0.0   \n",
      "3          0.0      12.320000          0.0          0.0             0.0   \n",
      "4          0.0     175.632857          0.0          0.0             0.0   \n",
      "\n",
      "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
      "0             0.0              0.0              0.0     86494.373514   \n",
      "1             0.0              0.0              0.0      1858.960000   \n",
      "2             0.0              0.0              0.0    592571.000000   \n",
      "3             0.0              0.0              0.0        12.320000   \n",
      "4             0.0              0.0              0.0       206.122143   \n",
      "\n",
      "   avg received 13  avg received 14  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "print(node_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features\n",
    "In terms of edge features, we would like to conside each transcation as edges.  \n",
    "For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]  \n",
    "For edge attributes, we used 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:06.006625Z",
     "iopub.status.busy": "2023-10-07T05:58:06.006227Z",
     "iopub.status.idle": "2023-10-07T05:58:06.015211Z",
     "shell.execute_reply": "2023-10-07T05:58:06.014356Z",
     "shell.execute_reply.started": "2023-10-07T05:58:06.006594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_edge_df(accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "#         edge_attr = torch.from_numpy(df.values).to(torch.float)  # comment for visualization\n",
    "\n",
    "        edge_attr = df  # for visualization\n",
    "        return edge_attr, edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_attr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T06:00:02.820037Z",
     "iopub.status.busy": "2023-10-07T06:00:02.819644Z",
     "iopub.status.idle": "2023-10-07T06:00:07.880960Z",
     "shell.execute_reply": "2023-10-07T06:00:07.879754Z",
     "shell.execute_reply.started": "2023-10-07T06:00:02.820005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
      "3408783   0.266147          8081.58                   4      8081.58   \n",
      "3986981   0.318925         47468.31                   4     47468.31   \n",
      "4804475   0.393400          8081.58                   4      8081.58   \n",
      "4804474   0.394151         47468.31                   4     47468.31   \n",
      "6690464   0.547730           787.72                   4       787.72   \n",
      "\n",
      "         Payment Currency  Payment Format  \n",
      "3408783                 4               4  \n",
      "3986981                 4               3  \n",
      "4804475                 4               4  \n",
      "4804474                 4               3  \n",
      "6690464                 4               3  \n"
     ]
    }
   ],
   "source": [
    "edge_attr, edge_index = get_edge_df(accounts, df)\n",
    "print(edge_attr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:16.265617Z",
     "iopub.status.busy": "2023-10-07T05:58:16.265045Z",
     "iopub.status.idle": "2023-10-07T05:58:16.274597Z",
     "shell.execute_reply": "2023-10-07T05:58:16.273471Z",
     "shell.execute_reply.started": "2023-10-07T05:58:16.265571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,      0,      0,  ..., 681281, 681282, 681282],\n",
      "        [ 22343,  22343,  22343,  ..., 681281, 681282, 681282]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code \n",
    "### Below we will show the final code for model.py, train.py and dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "In this section, we used Graph Attention Networks as our backbone model.  \n",
    "The model built with two GATConv layers followed by a linear layer with sigmoid outout for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv, Linear\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
    "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = self.lin(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyG InMemoryDataset\n",
    "Finally we can build the dataset with above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AMLtoGraph(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root: str, edge_window_size: int = 10,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        self.edge_window_size = edge_window_size\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'LI-Small_Trans.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self._data.edge_index.max().item() + 1\n",
    "\n",
    "    def df_label_encoder(self, df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls\n",
    "\n",
    "    def get_all_account(self, df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    \n",
    "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "        accounts = accounts.fillna(0)\n",
    "        return accounts\n",
    "\n",
    "    def get_edge_df(self, accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
    "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "        return node_df, node_label\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
    "        accounts = self.get_all_account(df)\n",
    "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
    "\n",
    "        data = Data(x=node_attr,\n",
    "                    edge_index=edge_index,\n",
    "                    y=node_label,\n",
    "                    edge_attr=edge_attr\n",
    "                    )\n",
    "        \n",
    "        data_list = [data] \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "As we cannot create folder in kaggle, please follow the instructions in https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN before you start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from 'c:\\\\Users\\\\jirap\\\\OneDrive\\\\Desktop\\\\Gits\\\\Anti-Money-Laundering-Datamining\\\\GNN\\\\dataset.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, dataset\n",
    "importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 28.9350, Val Loss: 36.0975, Val Acc: 0.6349\n",
      "Epoch: 020, Loss: 28.2222, Val Loss: 35.2105, Val Acc: 0.6442\n",
      "Epoch: 030, Loss: 28.2341, Val Loss: 34.6094, Val Acc: 0.6503\n",
      "Epoch: 040, Loss: 27.6121, Val Loss: 33.7354, Val Acc: 0.6592\n",
      "Epoch: 050, Loss: 30.7693, Val Loss: 32.8628, Val Acc: 0.6685\n",
      "Epoch: 060, Loss: 26.5314, Val Loss: 32.0509, Val Acc: 0.6770\n",
      "Epoch: 070, Loss: 27.8385, Val Loss: 28.6403, Val Acc: 0.7110\n",
      "Epoch: 080, Loss: 26.2114, Val Loss: 28.2124, Val Acc: 0.7158\n",
      "Epoch: 090, Loss: 26.7170, Val Loss: 27.6892, Val Acc: 0.7211\n",
      "Epoch: 100, Loss: 26.6882, Val Loss: 27.2748, Val Acc: 0.7252\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# กำหนดอุปกรณ์ประมวลผลและเตรียมข้อมูลกราฟจากไฟล์ที่ประมวลผลไว้แล้ว\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = AMLtoGraph('./data')\n",
    "data = dataset[0]\n",
    "epoch = 100\n",
    "\n",
    "# สร้างโมเดล GAT พร้อมฟังก์ชัน loss และ optimizer สำหรับเรียนรู้แบบทวิภาค\n",
    "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "data = split(data)\n",
    "data = data.to(device)\n",
    "\n",
    "# เทรนโมเดลกับกราฟเต็มโดยใช้ train_mask เพื่อคำนวณ loss\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = criterion(pred[data.train_mask], data.y[data.train_mask].unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # ประเมินผลบน validation mask ทุก 10 epoch\n",
    "    if (i + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "            val_probs = val_pred[data.val_mask]\n",
    "            val_labels = data.y[data.val_mask].unsqueeze(1)\n",
    "            val_loss = criterion(val_probs, val_labels)\n",
    "            val_acc = ((val_probs > 0.5).float() == val_labels).float().mean().item()\n",
    "        print(f\"Epoch: {i + 1:03d}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "Some of the feature engineering of this repo are referenced to below papers, highly recommend to read:\n",
    "1. [Weber, M., Domeniconi, G., Chen, J., Weidele, D. K. I., Bellei, C., Robinson, T., & Leiserson, C. E. (2019). Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. arXiv preprint arXiv:1908.02591.](https://arxiv.org/pdf/1908.02591.pdf)\n",
    "2. [Johannessen, F., & Jullum, M. (2023). Finding Money Launderers Using Heterogeneous Graph Neural Networks. arXiv preprint arXiv:2307.13499.](https://arxiv.org/pdf/2307.13499.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

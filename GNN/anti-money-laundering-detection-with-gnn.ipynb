{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Money Laundering Detection with GNN node classification\n",
    "### This notenook includes GNN model training and dataset implementation with PyG library. In this example, we used LI-Small_Trans.csv as our dataset for training and testing.  \n",
    "### For more details, please view https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-07T05:03:44.040372Z",
     "iopub.status.busy": "2023-10-07T05:03:44.039793Z",
     "iopub.status.idle": "2023-10-07T05:03:58.147392Z",
     "shell.execute_reply": "2023-10-07T05:03:58.146038Z",
     "shell.execute_reply.started": "2023-10-07T05:03:44.040343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Show all columns when print dataframe\n",
    "path = './data/raw/LI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and possible feature engineering\n",
    "Let's look into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:33:22.849494Z",
     "iopub.status.busy": "2023-10-07T05:33:22.849049Z",
     "iopub.status.idle": "2023-10-07T05:33:22.867501Z",
     "shell.execute_reply": "2023-10-07T05:33:22.866198Z",
     "shell.execute_reply.started": "2023-10-07T05:33:22.849448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "0  2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
      "1  2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
      "2  2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
      "3  2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
      "4  2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
      "\n",
      "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "0       3195403.00          US Dollar   3195403.00        US Dollar   \n",
      "1          1858.96          US Dollar      1858.96        US Dollar   \n",
      "2        592571.00          US Dollar    592571.00        US Dollar   \n",
      "3            12.32          US Dollar        12.32        US Dollar   \n",
      "4          2941.56          US Dollar      2941.56        US Dollar   \n",
      "\n",
      "  Payment Format  Is Laundering  \n",
      "0   Reinvestment              0  \n",
      "1   Reinvestment              0  \n",
      "2         Cheque              0  \n",
      "3   Reinvestment              0  \n",
      "4   Reinvestment              0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the viewing the dataframe, we suggest that we can extract all accounts from receiver and payer among all transcation for sorting the suspicious accounts. We can transform the whole dataset into node classification problem by considering accounts as nodes while transcation as edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object columns should be encoded into classes with sklearn LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:36:52.790986Z",
     "iopub.status.busy": "2023-10-07T05:36:52.790429Z",
     "iopub.status.idle": "2023-10-07T05:36:52.797831Z",
     "shell.execute_reply": "2023-10-07T05:36:52.796721Z",
     "shell.execute_reply.started": "2023-10-07T05:36:52.790952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp              object\n",
      "From Bank               int64\n",
      "Account                object\n",
      "To Bank                 int64\n",
      "Account.1              object\n",
      "Amount Received       float64\n",
      "Receiving Currency     object\n",
      "Amount Paid           float64\n",
      "Payment Currency       object\n",
      "Payment Format         object\n",
      "Is Laundering           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:40:11.526713Z",
     "iopub.status.busy": "2023-10-07T05:40:11.526397Z",
     "iopub.status.idle": "2023-10-07T05:40:12.913554Z",
     "shell.execute_reply": "2023-10-07T05:40:12.912335Z",
     "shell.execute_reply.started": "2023-10-07T05:40:11.526687Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp             0\n",
      "From Bank             0\n",
      "Account               0\n",
      "To Bank               0\n",
      "Account.1             0\n",
      "Amount Received       0\n",
      "Receiving Currency    0\n",
      "Amount Paid           0\n",
      "Payment Currency      0\n",
      "Payment Format        0\n",
      "Is Laundering         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns representing paid and received amount of each transcation, wondering if it is necessary to split the amount into two columns when they shared the same value, unless there are transcation fee/transcation between different currency. Let's find out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:45:40.568327Z",
     "iopub.status.busy": "2023-10-07T05:45:40.567898Z",
     "iopub.status.idle": "2023-10-07T05:45:40.594713Z",
     "shell.execute_reply": "2023-10-07T05:45:40.593358Z",
     "shell.execute_reply.started": "2023-10-07T05:45:40.568296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Received equals to Amount Paid:\n",
      "False\n",
      "Receiving Currency equals to Payment Currency:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Amount Received equals to Amount Paid:')\n",
    "print(df['Amount Received'].equals(df['Amount Paid']))\n",
    "print('Receiving Currency equals to Payment Currency:')\n",
    "print(df['Receiving Currency'].equals(df['Payment Currency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seens involved the transcations between different currency, let's print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:46:16.614934Z",
     "iopub.status.busy": "2023-10-07T05:46:16.614531Z",
     "iopub.status.idle": "2023-10-07T05:46:17.289425Z",
     "shell.execute_reply": "2023-10-07T05:46:17.288314Z",
     "shell.execute_reply.started": "2023-10-07T05:46:16.614907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98858 rows x 11 columns]\n",
      "---------------------------------------------------------------------------\n",
      "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "2770     2022/09/01 00:12        394  80056EDE0      394  80056EDE0   \n",
      "8081     2022/09/01 00:28      11701  800C95BF0    11701  800C95BF0   \n",
      "10451    2022/09/01 00:18      22481  80105E630    22481  80105E630   \n",
      "12948    2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
      "13799    2022/09/01 00:02         20  8015D68E0       20  8015D68E0   \n",
      "...                   ...        ...        ...      ...        ...   \n",
      "6924007  2022/09/10 23:57       9096  80356BD61     9096  80356BD60   \n",
      "6924009  2022/09/10 23:30       9096  80356BD61     9096  80356BD60   \n",
      "6924019  2022/09/10 23:38      13474  803A93631    13474  803A93630   \n",
      "6924021  2022/09/10 23:31      13474  803A93631    13474  803A93630   \n",
      "6924023  2022/09/10 23:56      13474  803A93631    13474  803A93630   \n",
      "\n",
      "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "2770           47.610000               Euro        55.79        US Dollar   \n",
      "8081          954.620000               Yuan       142.53        US Dollar   \n",
      "10451       16930.030000                Yen       160.63        US Dollar   \n",
      "12948          14.520000           UK Pound        18.76        US Dollar   \n",
      "13799          37.000000               Euro        43.35        US Dollar   \n",
      "...                  ...                ...          ...              ...   \n",
      "6924007         0.000005            Bitcoin         0.39             Yuan   \n",
      "6924009         0.000007            Bitcoin         0.55             Yuan   \n",
      "6924019         0.000007            Bitcoin         0.08        US Dollar   \n",
      "6924021         0.000020            Bitcoin         0.23        US Dollar   \n",
      "6924023         0.000001            Bitcoin         0.01        US Dollar   \n",
      "\n",
      "        Payment Format  Is Laundering  \n",
      "2770               ACH              0  \n",
      "8081               ACH              0  \n",
      "10451              ACH              0  \n",
      "12948              ACH              0  \n",
      "13799              ACH              0  \n",
      "...                ...            ...  \n",
      "6924007            ACH              0  \n",
      "6924009            ACH              0  \n",
      "6924019            ACH              0  \n",
      "6924021            ACH              0  \n",
      "6924023            ACH              0  \n",
      "\n",
      "[98876 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
    "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
    "print(not_equal1)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(not_equal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of two df shows that there are transcation fee and transcation between different currency, we cannot combine/drop the amount columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to encode the columns, we have to make sure that the classes of same attribute are aligned.\n",
    "Let's check if the list of Receiving Currency and Payment Currency are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:51:06.994519Z",
     "iopub.status.busy": "2023-10-07T05:51:06.994058Z",
     "iopub.status.idle": "2023-10-07T05:51:07.455980Z",
     "shell.execute_reply": "2023-10-07T05:51:07.454722Z",
     "shell.execute_reply.started": "2023-10-07T05:51:06.994490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
      "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df['Receiving Currency'].unique()))\n",
    "print(sorted(df['Payment Currency'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### We will show the functions used in the PyG dataset first, dataset and model training will be provided in bottom section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data preprocessing, we perform below transformation:  \n",
    "1. Transform the Timestamp with min max normalization.  \n",
    "2. Create unique ID for each account by adding bank code with account number.  \n",
    "3. Create receiving_df with the information of receiving accounts, received amount and currency\n",
    "4. Create paying_df with the information of payer accounts, paid amount and currency\n",
    "5. Create a list of currency used among all transactions\n",
    "6. Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:11.423289Z",
     "iopub.status.busy": "2023-10-07T05:53:11.422843Z",
     "iopub.status.idle": "2023-10-07T05:53:11.432504Z",
     "shell.execute_reply": "2023-10-07T05:53:11.431355Z",
     "shell.execute_reply.started": "2023-10-07T05:53:11.423245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ฟังก์ชันสำหรับเข้ารหัส (Label Encoding) ค่าที่เป็นข้อความ (categorical columns)\n",
    "def df_label_encoder(df, columns):\n",
    "    # สร้างอ็อบเจกต์ LabelEncoder จาก sklearn\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # วนลูปเข้ารหัสทุกคอลัมน์ที่ระบุ\n",
    "    for i in columns:\n",
    "        # แปลงค่าทั้งหมดในคอลัมน์เป็น string แล้วเข้ารหัสเป็นตัวเลข\n",
    "        df[i] = le.fit_transform(df[i].astype(str))\n",
    "    \n",
    "    # คืนค่า DataFrame หลังจากเข้ารหัสแล้ว\n",
    "    return df\n",
    "\n",
    "\n",
    "# ฟังก์ชันสำหรับเตรียมข้อมูลก่อนนำเข้าโมเดล (Data Preprocessing)\n",
    "def preprocess(df):\n",
    "    # 1 เข้ารหัสคอลัมน์ที่เป็นข้อความ (Payment Format, Payment Currency, Receiving Currency)\n",
    "    df = df_label_encoder(df, ['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "\n",
    "    # 2️ แปลงคอลัมน์ Timestamp จาก string → datetime object\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    # 3️ แปลง Timestamp เป็นค่าตัวเลข (จำนวน nanoseconds นับจาก epoch)\n",
    "    df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "\n",
    "    # 4️ ทำการ Normalize ค่า Timestamp ให้อยู่ในช่วง [0, 1]\n",
    "    df['Timestamp'] = (df['Timestamp'] - df['Timestamp'].min()) / (df['Timestamp'].max() - df['Timestamp'].min())\n",
    "\n",
    "    # 5️ รวมรหัสธนาคารกับหมายเลขบัญชีเพื่อสร้างรหัสบัญชีที่ไม่ซ้ำ (unique account ID)\n",
    "    # เช่น \"11\" (From Bank) + \"_\" + \"8000ECA90\" (Account) → \"11_8000ECA90\"\n",
    "    df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "    df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "\n",
    "    # 6️ เรียงลำดับข้อมูลตามชื่อบัญชี เพื่อให้ข้อมูลมีลำดับที่คงที่\n",
    "    df = df.sort_values(by=['Account'])\n",
    "\n",
    "    # 7️ สร้าง DataFrame ของบัญชีผู้รับ (receiving_df)\n",
    "    # มีข้อมูล: บัญชีผู้รับ, จำนวนเงินที่ได้รับ, และรหัสสกุลเงิน\n",
    "    receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "\n",
    "    # 8️ สร้าง DataFrame ของบัญชีผู้จ่าย (paying_df)\n",
    "    # มีข้อมูล: บัญชีผู้จ่าย, จำนวนเงินที่จ่าย, และรหัสสกุลเงิน\n",
    "    paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "\n",
    "    # 9️ เปลี่ยนชื่อคอลัมน์ Account.1 → Account เพื่อให้ชื่อสอดคล้องกับฝั่งผู้จ่าย\n",
    "    receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "\n",
    "    #  ดึงรายการสกุลเงินทั้งหมดที่ปรากฏในข้อมูล และจัดเรียงให้อยู่ในลำดับคงที่\n",
    "    currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "    return df, receiving_df, paying_df, currency_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look of processed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:15.266963Z",
     "iopub.status.busy": "2023-10-07T05:53:15.266592Z",
     "iopub.status.idle": "2023-10-07T05:53:56.218064Z",
     "shell.execute_reply": "2023-10-07T05:53:56.216975Z",
     "shell.execute_reply.started": "2023-10-07T05:53:15.266935Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  From Bank      Account  To Bank        Account.1  \\\n",
      "3408783   0.266147          0  0_800060CE0    11314  11314_800990320   \n",
      "3986981   0.318925          0  0_800060CE0    11314  11314_800990320   \n",
      "4804475   0.393400          0  0_800060CE0    11314  11314_800990320   \n",
      "4804474   0.394151          0  0_800060CE0    11314  11314_800990320   \n",
      "6690464   0.547730          0  0_800060CE0     1390   1390_800E49870   \n",
      "\n",
      "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
      "3408783          8081.58                   4      8081.58                 4   \n",
      "3986981         47468.31                   4     47468.31                 4   \n",
      "4804475          8081.58                   4      8081.58                 4   \n",
      "4804474         47468.31                   4     47468.31                 4   \n",
      "6690464           787.72                   4       787.72                 4   \n",
      "\n",
      "         Payment Format  Is Laundering  \n",
      "3408783               4              0  \n",
      "3986981               3              0  \n",
      "4804475               4              0  \n",
      "4804474               3              0  \n",
      "6690464               3              0  \n"
     ]
    }
   ],
   "source": [
    "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paying df and receiving df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:25.918744Z",
     "iopub.status.busy": "2023-10-07T05:57:25.918280Z",
     "iopub.status.idle": "2023-10-07T05:57:25.929797Z",
     "shell.execute_reply": "2023-10-07T05:57:25.928625Z",
     "shell.execute_reply.started": "2023-10-07T05:57:25.918708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Account  Amount Received  Receiving Currency\n",
      "3408783  11314_800990320          8081.58                   4\n",
      "3986981  11314_800990320         47468.31                   4\n",
      "4804475  11314_800990320          8081.58                   4\n",
      "4804474  11314_800990320         47468.31                   4\n",
      "6690464   1390_800E49870           787.72                   4\n",
      "             Account  Amount Paid  Payment Currency\n",
      "3408783  0_800060CE0      8081.58                 4\n",
      "3986981  0_800060CE0     47468.31                 4\n",
      "4804475  0_800060CE0      8081.58                 4\n",
      "4804474  0_800060CE0     47468.31                 4\n",
      "6690464  0_800060CE0       787.72                 4\n"
     ]
    }
   ],
   "source": [
    "print(receiving_df.head())\n",
    "print(paying_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currency_ls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:28.907031Z",
     "iopub.status.busy": "2023-10-07T05:57:28.906667Z",
     "iopub.status.idle": "2023-10-07T05:57:28.913761Z",
     "shell.execute_reply": "2023-10-07T05:57:28.912327Z",
     "shell.execute_reply.started": "2023-10-07T05:57:28.907004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14)]\n"
     ]
    }
   ],
   "source": [
    "print(currency_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.  \n",
    "In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with 'Is Laundering' == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:31.850839Z",
     "iopub.status.busy": "2023-10-07T05:57:31.850459Z",
     "iopub.status.idle": "2023-10-07T05:57:31.858990Z",
     "shell.execute_reply": "2023-10-07T05:57:31.857826Z",
     "shell.execute_reply.started": "2023-10-07T05:57:31.850810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_all_account(df):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้มีหน้าที่รวบรวมบัญชีทั้งหมดจากทั้งฝั่งผู้โอน (payer) และผู้รับ (receiver)\n",
    "    เพื่อสร้างรายการบัญชีที่ใช้เป็นโหนด (nodes) ในกราฟของระบบตรวจจับการฟอกเงิน\n",
    "    พร้อมกำหนดค่าป้ายกำกับ (label) ให้แต่ละบัญชีว่าเป็นบัญชีปกติ (0) หรือเป็นบัญชีที่เกี่ยวข้องกับการฟอกเงิน (1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #ดึงเฉพาะข้อมูลฝั่งผู้โอน (payer) ประกอบด้วย Account และรหัสธนาคารต้นทาง\n",
    "    ldf = df[['Account', 'From Bank']]\n",
    "\n",
    "    # ดึงเฉพาะข้อมูลฝั่งผู้รับ (receiver) ประกอบด้วย Account.1 และรหัสธนาคารปลายทาง\n",
    "    rdf = df[['Account.1', 'To Bank']]\n",
    "\n",
    "    # เลือกเฉพาะธุรกรรมที่มีการฟอกเงิน (Is Laundering == 1)\n",
    "    suspicious = df[df['Is Laundering'] == 1]\n",
    "\n",
    "    # ดึงบัญชีฝั่งผู้โอนที่อยู่ในธุรกรรมฟอกเงิน\n",
    "    s1 = suspicious[['Account', 'Is Laundering']]\n",
    "\n",
    "    # ดึงบัญชีฝั่งผู้รับที่อยู่ในธุรกรรมฟอกเงิน\n",
    "    s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "\n",
    "    # เปลี่ยนชื่อคอลัมน์ 'Account.1' เป็น 'Account'\n",
    "    # เพื่อให้ชื่อคอลัมน์ของ s2 สอดคล้องกับ s1 สำหรับการรวมกันภายหลัง\n",
    "    s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "\n",
    "    # รวมข้อมูลบัญชีผู้โอนและผู้รับที่เกี่ยวข้องกับฟอกเงินเข้าด้วยกัน\n",
    "    suspicious = pd.concat([s1, s2], join='outer')\n",
    "\n",
    "    # ลบบัญชีซ้ำออก เพื่อให้เหลือบัญชีที่น่าสงสัยแต่ละบัญชีเพียง 1 ครั้ง\n",
    "    suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "\n",
    "    # เปลี่ยนชื่อคอลัมน์ของ ldf และ rdf ให้เป็นชื่อเดียวกัน (Bank, Account)\n",
    "    # จากนั้นเราจะรวมบัญชีฝั่งผู้โอนและผู้รับทั้งหมดเข้าด้วยกัน\n",
    "    ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "    rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "\n",
    "    # รวมตารางฝั่งผู้โอนและผู้รับทั้งหมดเป็นตารางเดียว (รวมทุกบัญชีที่เคยปรากฏในระบบ)\n",
    "    df = pd.concat([ldf, rdf], join='outer')\n",
    "\n",
    "    # ลบบัญชีซ้ำ (เช่น บัญชีที่เคยเป็นทั้งผู้โอนและผู้รับ)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    #  เริ่มต้นกำหนดคอลัมน์ 'Is Laundering' ให้ทุกบัญชีเป็น 0 (ถือว่าปกติ)\n",
    "    df['Is Laundering'] = 0\n",
    "\n",
    "    # ตั้ง 'Account' เป็น index เพื่อให้ update ข้อมูลตามชื่อบัญชีได้ง่าย\n",
    "    df.set_index('Account', inplace=True)\n",
    "\n",
    "    #  อัปเดตค่าของบัญชีที่น่าสงสัย (จาก suspicious DataFrame)\n",
    "    # โดยจะเขียนทับเฉพาะบัญชีที่อยู่ในรายการฟอกเงิน (Is Laundering = 1)\n",
    "    df.update(suspicious.set_index('Account'))\n",
    "\n",
    "    # รีเซ็ต index กลับมาเป็นคอลัมน์ปกติ\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look of the account list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:34.379521Z",
     "iopub.status.busy": "2023-10-07T05:57:34.378456Z",
     "iopub.status.idle": "2023-10-07T05:57:41.317058Z",
     "shell.execute_reply": "2023-10-07T05:57:41.316062Z",
     "shell.execute_reply.started": "2023-10-07T05:57:34.379481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Account  Bank  Is Laundering\n",
      "0  0_800060CE0     0              0\n",
      "1  0_800061260     0              0\n",
      "2  0_800062D90     0              0\n",
      "3  0_800062F80     0              0\n",
      "4  0_800064980     0              0\n"
     ]
    }
   ],
   "source": [
    "accounts = get_all_account(df)\n",
    "print(accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node features\n",
    "For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:43.694369Z",
     "iopub.status.busy": "2023-10-07T05:57:43.693958Z",
     "iopub.status.idle": "2023-10-07T05:57:43.701141Z",
     "shell.execute_reply": "2023-10-07T05:57:43.699901Z",
     "shell.execute_reply.started": "2023-10-07T05:57:43.694334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้มีหน้าที่คำนวณค่าเฉลี่ยของจำนวนเงินที่ 'จ่ายออก' (Amount Paid)\n",
    "    แยกตามแต่ละสกุลเงิน (Payment Currency)\n",
    "    แล้วเพิ่มเป็นคอลัมน์ใหม่ให้กับ DataFrame ของบัญชี (accounts)\n",
    "    \"\"\"\n",
    "    # วนลูปผ่านทุกสกุลเงินในรายการ\n",
    "    for i in currency_ls:\n",
    "        # เลือกเฉพาะธุรกรรมที่มีสกุลเงินตรงกับค่าปัจจุบัน i\n",
    "        temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "\n",
    "        # คำนวณค่าเฉลี่ยของ Amount Paid ต่อบัญชี (Account)\n",
    "        # แล้วเพิ่มผลลัพธ์เป็นคอลัมน์ใหม่ใน accounts\n",
    "        accounts['avg paid ' + str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "    \n",
    "    return accounts\n",
    "\n",
    "\n",
    "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้มีหน้าที่คำนวณค่าเฉลี่ยของจำนวนเงินที่ 'ได้รับ' (Amount Received)\n",
    "    แยกตามแต่ละสกุลเงิน (Receiving Currency)\n",
    "    แล้วเพิ่มเป็นคอลัมน์ใหม่ให้กับ DataFrame ของบัญชี (accounts)\n",
    "    \"\"\"\n",
    "    # วนลูปผ่านทุกสกุลเงินในรายการ\n",
    "    for i in currency_ls:\n",
    "        # เลือกเฉพาะธุรกรรมที่มีสกุลเงินตรงกับค่าปัจจุบัน i\n",
    "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "\n",
    "        # คำนวณค่าเฉลี่ยของ Amount Received ต่อบัญชี (Account)\n",
    "        # แล้วเพิ่มผลลัพธ์เป็นคอลัมน์ใหม่ใน accounts\n",
    "        accounts['avg received ' + str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "    \n",
    "    # เติมค่าที่หายไป (NaN) ด้วย 0 เพื่อป้องกันปัญหาขณะนำไปใช้กับโมเดล\n",
    "    accounts = accounts.fillna(0)\n",
    "\n",
    "    return accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:45.915808Z",
     "iopub.status.busy": "2023-10-07T05:57:45.915112Z",
     "iopub.status.idle": "2023-10-07T05:57:45.926442Z",
     "shell.execute_reply": "2023-10-07T05:57:45.924963Z",
     "shell.execute_reply.started": "2023-10-07T05:57:45.915734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_node_attr(currency_ls, paying_df, receiving_df, accounts):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้มีหน้าที่สร้าง \"คุณลักษณะของโหนด (Node Attributes)\" \n",
    "    และ \"ป้ายกำกับของโหนด (Node Labels)\" สำหรับแต่ละบัญชี\n",
    "    เพื่อนำไปใช้เป็นข้อมูลป้อนเข้าโมเดลกราฟ (Graph Neural Network)\n",
    "    \"\"\"\n",
    "\n",
    "    # ขั้นตอนที่ 1: รวมฟีเจอร์การจ่ายเงินของแต่ละบัญชีตามสกุลเงิน\n",
    "    node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "\n",
    "    # ขั้นตอนที่ 2: รวมฟีเจอร์การรับเงินของแต่ละบัญชีตามสกุลเงิน\n",
    "    node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "\n",
    "    # ขั้นตอนที่ 3: แปลงค่าป้ายกำกับ (Is Laundering) ให้เป็น tensor ของ PyTorch\n",
    "    # ใช้ torch.float เพื่อให้สามารถใช้กับฟังก์ชัน Loss ได้\n",
    "    node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "\n",
    "    # ขั้นตอนที่ 4: ลบคอลัมน์ที่ไม่ต้องใช้ในการเทรนโมเดลออก (Account, Is Laundering)\n",
    "    node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "\n",
    "    # ขั้นตอนที่ 5: เข้ารหัส (Label Encoding) คอลัมน์ 'Bank' \n",
    "    # เพื่อให้รหัสธนาคารเป็นค่าตัวเลขที่โมเดลเข้าใจได้\n",
    "    node_df = df_label_encoder(node_df, ['Bank'])\n",
    "\n",
    "    # node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "\n",
    "    return node_df, node_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look of node_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:48.258031Z",
     "iopub.status.busy": "2023-10-07T05:57:48.257639Z",
     "iopub.status.idle": "2023-10-07T05:57:56.275657Z",
     "shell.execute_reply": "2023-10-07T05:57:56.274417Z",
     "shell.execute_reply.started": "2023-10-07T05:57:48.257999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
      "0     0         0.0         0.0         0.0         0.0         0.0   \n",
      "1     0         0.0         0.0         0.0         0.0         0.0   \n",
      "2     0         0.0         0.0         0.0         0.0         0.0   \n",
      "3     0         0.0         0.0         0.0         0.0         0.0   \n",
      "4     0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "\n",
      "   avg paid 11    avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
      "0          0.0  307628.336486          0.0          0.0             0.0   \n",
      "1          0.0    1858.960000          0.0          0.0             0.0   \n",
      "2          0.0  307628.336486          0.0          0.0             0.0   \n",
      "3          0.0      12.320000          0.0          0.0             0.0   \n",
      "4          0.0     175.632857          0.0          0.0             0.0   \n",
      "\n",
      "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
      "0             0.0              0.0              0.0     86494.373514   \n",
      "1             0.0              0.0              0.0      1858.960000   \n",
      "2             0.0              0.0              0.0    592571.000000   \n",
      "3             0.0              0.0              0.0        12.320000   \n",
      "4             0.0              0.0              0.0       206.122143   \n",
      "\n",
      "   avg received 13  avg received 14  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "print(node_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features\n",
    "In terms of edge features, we would like to conside each transcation as edges.  \n",
    "For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]  \n",
    "For edge attributes, we used 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:06.006625Z",
     "iopub.status.busy": "2023-10-07T05:58:06.006227Z",
     "iopub.status.idle": "2023-10-07T05:58:06.015211Z",
     "shell.execute_reply": "2023-10-07T05:58:06.014356Z",
     "shell.execute_reply.started": "2023-10-07T05:58:06.006594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_edge_df(accounts, df):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้มีหน้าที่สร้างข้อมูลของ \"ขอบของกราฟ (edges)\" \n",
    "    สำหรับโมเดลกราฟ (Graph Neural Network) โดยแปลงข้อมูลธุรกรรมแต่ละรายการ \n",
    "    ให้กลายเป็นขอบระหว่างโหนดต้นทาง (ผู้โอน) และโหนดปลายทาง (ผู้รับ)\n",
    "    \"\"\"\n",
    "\n",
    "    # ขั้นตอนที่ 1: รีเซ็ต index ของ accounts เพื่อให้แน่ใจว่า index เรียงลำดับใหม่จาก 0\n",
    "    accounts = accounts.reset_index(drop=True)\n",
    "\n",
    "    # ขั้นตอนที่ 2: สร้างคอลัมน์ 'ID' โดยใช้ค่า index เป็นรหัสของแต่ละบัญชี\n",
    "    accounts['ID'] = accounts.index\n",
    "\n",
    "    # ขั้นตอนที่ 3: สร้างพจนานุกรม (dictionary) สำหรับ map จากชื่อบัญชี → หมายเลข ID\n",
    "    mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "\n",
    "    # ขั้นตอนที่ 4: ใช้ mapping_dict เพื่อแปลงชื่อบัญชีในธุรกรรม\n",
    "    # ให้กลายเป็นหมายเลข ID ของบัญชีต้นทาง (From) และปลายทาง (To)\n",
    "    df['From'] = df['Account'].map(mapping_dict)\n",
    "    df['To'] = df['Account.1'].map(mapping_dict)\n",
    "\n",
    "    # ขั้นตอนที่ 5: ลบคอลัมน์ที่ไม่จำเป็นสำหรับการสร้างกราฟออก\n",
    "    # (เช่น Account ชื่อจริง, รหัสธนาคารต้นทาง/ปลายทาง)\n",
    "    df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "    # ขั้นตอนที่ 6: สร้าง tensor edge_index ที่เก็บคู่ (from, to) ของแต่ละธุรกรรม\n",
    "    # shape = [2, จำนวนธุรกรรมทั้งหมด]\n",
    "    edge_index = torch.stack([\n",
    "        torch.from_numpy(df['From'].values),\n",
    "        torch.from_numpy(df['To'].values)\n",
    "    ], dim=0)\n",
    "\n",
    "    # ขั้นตอนที่ 7: ลบคอลัมน์ที่ไม่ต้องการใน edge attribute\n",
    "    # เช่น Is Laundering (label ของโหนด), และ index mapping ชั่วคราว\n",
    "    df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "    # edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
    "\n",
    "    # ใช้ DataFrame ดิบเป็น edge_attr แทน (เพื่อดูค่าได้ง่ายขณะทดลอง)\n",
    "    edge_attr = df\n",
    "\n",
    "    return edge_attr, edge_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_attr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T06:00:02.820037Z",
     "iopub.status.busy": "2023-10-07T06:00:02.819644Z",
     "iopub.status.idle": "2023-10-07T06:00:07.880960Z",
     "shell.execute_reply": "2023-10-07T06:00:07.879754Z",
     "shell.execute_reply.started": "2023-10-07T06:00:02.820005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
      "3408783   0.266147          8081.58                   4      8081.58   \n",
      "3986981   0.318925         47468.31                   4     47468.31   \n",
      "4804475   0.393400          8081.58                   4      8081.58   \n",
      "4804474   0.394151         47468.31                   4     47468.31   \n",
      "6690464   0.547730           787.72                   4       787.72   \n",
      "\n",
      "         Payment Currency  Payment Format  \n",
      "3408783                 4               4  \n",
      "3986981                 4               3  \n",
      "4804475                 4               4  \n",
      "4804474                 4               3  \n",
      "6690464                 4               3  \n"
     ]
    }
   ],
   "source": [
    "edge_attr, edge_index = get_edge_df(accounts, df)\n",
    "print(edge_attr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:16.265617Z",
     "iopub.status.busy": "2023-10-07T05:58:16.265045Z",
     "iopub.status.idle": "2023-10-07T05:58:16.274597Z",
     "shell.execute_reply": "2023-10-07T05:58:16.273471Z",
     "shell.execute_reply.started": "2023-10-07T05:58:16.265571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,      0,      0,  ..., 681281, 681282, 681282],\n",
      "        [ 22343,  22343,  22343,  ..., 681281, 681282, 681282]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code \n",
    "### Below we will show the final code for model.py, train.py and dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "In this section, we used Graph Attention Networks as our backbone model.  \n",
    "The model built with two GATConv layers followed by a linear layer with sigmoid outout for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv, Linear\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    คลาสนี้เป็นการนิยามโมเดล Graph Attention Network (GAT)\n",
    "    สำหรับงานจำแนกโหนด (Node Classification) เพื่อระบุว่าบัญชีใดมีพฤติกรรมฟอกเงินหรือไม่\n",
    "\n",
    "    โครงสร้างโมเดล:\n",
    "        - GATConv ชั้นที่ 1: เรียนรู้ความสัมพันธ์ระหว่างโหนด (ด้วย attention)\n",
    "        - GATConv ชั้นที่ 2: ย่อยข้อมูลที่ผ่านการเรียนรู้จากชั้นแรก\n",
    "        - Linear: แปลงข้อมูลที่ได้เป็นผลลัพธ์สำหรับการจำแนก\n",
    "        - Sigmoid: ทำให้ออกมาเป็นค่าความน่าจะเป็น (0–1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        # เรียกใช้ constructor ของคลาสแม่ (torch.nn.Module)\n",
    "        super().__init__()\n",
    "\n",
    "        # ชั้นแรกของ GAT: ใช้ attention หลายหัว (multi-head attention)\n",
    "        # เพื่อให้โมเดลเรียนรู้การเชื่อมโยงระหว่างโหนดที่ซับซ้อนได้ดีขึ้น\n",
    "        self.conv1 = GATConv(\n",
    "            in_channels,       # จำนวนฟีเจอร์อินพุตของโหนด\n",
    "            hidden_channels,   # จำนวนฟีเจอร์เอาต์พุตหลังชั้นนี้\n",
    "            heads,             # จำนวน attention heads\n",
    "            dropout=0.6        # dropout ระหว่างการเรียนรู้\n",
    "        )\n",
    "\n",
    "        # ชั้นที่สองของ GAT: ลดขนาดของฟีเจอร์ (hidden_channels/4)\n",
    "        # concat=False หมายความว่า output จากหลาย heads จะถูกเฉลี่ยรวมกัน\n",
    "        self.conv2 = GATConv(\n",
    "            hidden_channels * heads,  # input = output จากชั้นแรก (รวมทุก head)\n",
    "            int(hidden_channels / 4), # ลดมิติลงเพื่อป้องกัน overfitting\n",
    "            heads=1,                  # ใช้ head เดียวพอในชั้นที่สอง\n",
    "            concat=False,             # ไม่ต่อผลของหลายหัวเข้าด้วยกัน\n",
    "            dropout=0.6\n",
    "        )\n",
    "\n",
    "        # เลเยอร์ Linear: แปลงฟีเจอร์จาก GATConv สุดท้ายให้เป็นขนาดที่ต้องการ (out_channels)\n",
    "        self.lin = Linear(int(hidden_channels / 4), out_channels)\n",
    "\n",
    "        # Sigmoid: แปลงค่าเอาต์พุตสุดท้ายให้อยู่ในช่วง [0, 1] (เหมาะกับ binary classification)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        ฟังก์ชัน forward() คือการกำหนดลำดับขั้นตอนการไหลของข้อมูลในโมเดล\n",
    "        โดยรับข้อมูลของกราฟแล้วส่งผ่านแต่ละเลเยอร์\n",
    "        \"\"\"\n",
    "\n",
    "        # ขั้นตอนที่ 1: Dropout เพื่อป้องกัน overfitting\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "\n",
    "        # ขั้นตอนที่ 2: ผ่าน GATConv ชั้นที่ 1 พร้อมฟังก์ชันกระตุ้น ELU\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "\n",
    "        # ขั้นตอนที่ 3: Dropout อีกครั้งเพื่อเพิ่มความทนต่อ overfitting\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "\n",
    "        # ขั้นตอนที่ 4: ผ่าน GATConv ชั้นที่ 2 พร้อมฟังก์ชัน ELU\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "\n",
    "        # ขั้นตอนที่ 5: ผ่านเลเยอร์ Linear เพื่อให้ได้ขนาดเอาต์พุตสุดท้าย\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # ขั้นตอนที่ 6: ใช้ Sigmoid เพื่อแปลงให้อยู่ในช่วง [0, 1]\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        # คืนค่าผลลัพธ์สุดท้าย\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyG InMemoryDataset\n",
    "Finally we can build the dataset with above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AMLtoGraph(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    คลาสนี้ใช้สำหรับสร้างชุดข้อมูลกราฟ (Graph Dataset)\n",
    "    จากข้อมูลธุรกรรมทางการเงิน เพื่อนำไปใช้เทรนโมเดลตรวจจับการฟอกเงิน (GNN)\n",
    "\n",
    "    การทำงานหลักของคลาสนี้:\n",
    "        1. โหลดข้อมูล CSV ดิบ\n",
    "        2. ทำการแปลงและเตรียมข้อมูล (Preprocess)\n",
    "        3. สร้างโหนด (Nodes) จากบัญชีทั้งหมด\n",
    "        4. สร้างขอบ (Edges) จากธุรกรรมแต่ละรายการ\n",
    "        5. สร้างฟีเจอร์ของโหนดและขอบ (Attributes)\n",
    "        6. รวมทั้งหมดเป็นอ็อบเจกต์ของ PyTorch Geometric Data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str, edge_window_size: int = 10,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        # บันทึกค่า edge_window_size ไว้ในคลาส\n",
    "        self.edge_window_size = edge_window_size\n",
    "\n",
    "        # เรียกใช้งาน constructor ของคลาสแม่ InMemoryDataset\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "        # โหลดข้อมูลที่ประมวลผลไว้แล้ว (processed data) จากไฟล์ data.pt\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ส่วนกำหนดชื่อไฟล์ที่ใช้ (สำหรับระบบของ PyTorch Geometric)\n",
    "    # ------------------------------------------------------------\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        # ชื่อไฟล์ข้อมูลต้นฉบับ (ต้องอยู่ในโฟลเดอร์ raw/)\n",
    "        return 'LI-Small_Trans.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        # ชื่อไฟล์ที่เก็บข้อมูลหลังประมวลผลเสร็จแล้ว\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        # จำนวนโหนดทั้งหมดในกราฟ\n",
    "        # โดยดูจากหมายเลขโหนดสูงสุดใน edge_index + 1\n",
    "        return self._data.edge_index.max().item() + 1\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: เข้ารหัสข้อมูลเชิงหมวดหมู่เป็นตัวเลข\n",
    "    # ------------------------------------------------------------\n",
    "    def df_label_encoder(self, df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: เตรียมข้อมูล (Preprocessing)\n",
    "    # ------------------------------------------------------------\n",
    "    def preprocess(self, df):\n",
    "        # เข้ารหัสคอลัมน์เชิงหมวดหมู่ (เช่น สกุลเงิน, รูปแบบการชำระเงิน)\n",
    "        df = self.df_label_encoder(df, ['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "\n",
    "        # แปลงเวลาเป็น datetime และ normalize ให้อยู่ในช่วง [0, 1]\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp'] - df['Timestamp'].min()) / (df['Timestamp'].max() - df['Timestamp'].min())\n",
    "\n",
    "        # รวมรหัสธนาคารกับหมายเลขบัญชี เพื่อสร้างรหัสบัญชีไม่ซ้ำ\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "\n",
    "        # เรียงข้อมูลตามชื่อบัญชีเพื่อความสม่ำเสมอ\n",
    "        df = df.sort_values(by=['Account'])\n",
    "\n",
    "        # แยกข้อมูลฝั่งผู้รับและผู้จ่ายออกมา\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "\n",
    "        # เปลี่ยนชื่อคอลัมน์ Account.1 → Account เพื่อให้ชื่อสอดคล้องกัน\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "\n",
    "        # เก็บรายการรหัสสกุลเงินทั้งหมด\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: สร้างตารางบัญชีทั้งหมด (Nodes)\n",
    "    # ------------------------------------------------------------\n",
    "    def get_all_account(self, df):\n",
    "        # ดึงข้อมูลบัญชีจากฝั่งผู้โอนและผู้รับ\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "\n",
    "        # ดึงธุรกรรมที่ถูกระบุว่าฟอกเงิน\n",
    "        suspicious = df[df['Is Laundering'] == 1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer').drop_duplicates()\n",
    "\n",
    "        # รวมข้อมูลผู้โอนและผู้รับทั้งหมด\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer').drop_duplicates()\n",
    "\n",
    "        # เพิ่มคอลัมน์ Is Laundering เริ่มต้นเป็น 0\n",
    "        df['Is Laundering'] = 0\n",
    "\n",
    "        # อัปเดตค่าของบัญชีที่เกี่ยวข้องกับการฟอกเงินให้เป็น 1\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: คำนวณค่าเฉลี่ยการจ่ายเงินแยกตามสกุลเงิน\n",
    "    # ------------------------------------------------------------\n",
    "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid ' + str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: คำนวณค่าเฉลี่ยการรับเงินแยกตามสกุลเงิน\n",
    "    # ------------------------------------------------------------\n",
    "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "            accounts['avg received ' + str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "        accounts = accounts.fillna(0)\n",
    "        return accounts\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: สร้างข้อมูลขอบ (Edges)\n",
    "    # ------------------------------------------------------------\n",
    "    def get_edge_df(self, accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "\n",
    "        # แปลงชื่อบัญชีในธุรกรรมให้เป็นหมายเลข ID\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "\n",
    "        # ลบคอลัมน์ที่ไม่จำเป็น\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        # สร้าง tensor edge_index ที่เก็บคู่ (from, to)\n",
    "        edge_index = torch.stack([\n",
    "            torch.from_numpy(df['From'].values),\n",
    "            torch.from_numpy(df['To'].values)\n",
    "        ], dim=0)\n",
    "\n",
    "        # ลบคอลัมน์ที่ไม่ต้องการออกจาก edge attribute\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "        # แปลงค่า edge attributes เป็น tensor ของตัวเลขแบบ float\n",
    "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันย่อย: สร้างฟีเจอร์และ label ของโหนด\n",
    "    # ------------------------------------------------------------\n",
    "    def get_node_attr(self, currency_ls, paying_df, receiving_df, accounts):\n",
    "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "\n",
    "        # Label ของโหนด (0 = ปกติ, 1 = ฟอกเงิน)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "\n",
    "        # ลบคอลัมน์ที่ไม่ใช้\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "\n",
    "        # เข้ารหัสคอลัมน์ 'Bank' เป็นตัวเลข\n",
    "        node_df = self.df_label_encoder(node_df, ['Bank'])\n",
    "\n",
    "        # แปลงข้อมูลฟีเจอร์เป็น tensor\n",
    "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "        return node_df, node_label\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # ฟังก์ชันหลัก: ประมวลผลข้อมูลและสร้างกราฟ\n",
    "    # ------------------------------------------------------------\n",
    "    def process(self):\n",
    "        # โหลดข้อมูลจากไฟล์ CSV ดิบ\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "\n",
    "        # ทำการ preprocess และแยกข้อมูลออกเป็นส่วนต่าง ๆ\n",
    "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
    "\n",
    "        # สร้างตารางบัญชีทั้งหมด (nodes)\n",
    "        accounts = self.get_all_account(df)\n",
    "\n",
    "        # สร้างคุณลักษณะของโหนดและป้ายกำกับ\n",
    "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df, receiving_df, accounts)\n",
    "\n",
    "        # สร้างข้อมูลขอบ (edges)\n",
    "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
    "\n",
    "        # สร้างอ็อบเจกต์ Data ของ PyTorch Geometric\n",
    "        data = Data(\n",
    "            x=node_attr,\n",
    "            edge_index=edge_index,\n",
    "            y=node_label,\n",
    "            edge_attr=edge_attr\n",
    "        )\n",
    "\n",
    "        # จัดเก็บข้อมูลเป็น list เดียว (กรณีมีหลายกราฟ)\n",
    "        data_list = [data]\n",
    "\n",
    "        # ตรวจสอบ pre_filter (ถ้ามี)\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "        # ตรวจสอบ pre_transform (ถ้ามี)\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        # รวมข้อมูลและบันทึกไฟล์ที่ประมวลผลแล้ว\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "As we cannot create folder in kaggle, please follow the instructions in https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN before you start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from 'c:\\\\Users\\\\jirap\\\\OneDrive\\\\Desktop\\\\Gits\\\\Anti-Money-Laundering-Datamining\\\\GNN\\\\dataset.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, dataset\n",
    "importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 28.9350, Val Loss: 36.0975, Val Acc: 0.6349\n",
      "Epoch: 020, Loss: 28.2222, Val Loss: 35.2105, Val Acc: 0.6442\n",
      "Epoch: 030, Loss: 28.2341, Val Loss: 34.6094, Val Acc: 0.6503\n",
      "Epoch: 040, Loss: 27.6121, Val Loss: 33.7354, Val Acc: 0.6592\n",
      "Epoch: 050, Loss: 30.7693, Val Loss: 32.8628, Val Acc: 0.6685\n",
      "Epoch: 060, Loss: 26.5314, Val Loss: 32.0509, Val Acc: 0.6770\n",
      "Epoch: 070, Loss: 27.8385, Val Loss: 28.6403, Val Acc: 0.7110\n",
      "Epoch: 080, Loss: 26.2114, Val Loss: 28.2124, Val Acc: 0.7158\n",
      "Epoch: 090, Loss: 26.7170, Val Loss: 27.6892, Val Acc: 0.7211\n",
      "Epoch: 100, Loss: 26.6882, Val Loss: 27.2748, Val Acc: 0.7252\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) กำหนดอุปกรณ์ประมวลผล (Device)\n",
    "# ------------------------------------------------------------\n",
    "# ถ้ามี GPU จะใช้ 'cuda' ถ้าไม่มีก็ใช้ 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) โหลดข้อมูลกราฟที่ถูกประมวลผลไว้แล้ว (จาก data.pt)\n",
    "# ------------------------------------------------------------\n",
    "# root='./data' คือโฟลเดอร์ที่มีไฟล์ processed/data.pt\n",
    "dataset = AMLtoGraph('./data')\n",
    "\n",
    "# ดึงกราฟแรกจาก dataset (กรณีมีเพียงกราฟเดียว)\n",
    "data = dataset[0]\n",
    "\n",
    "# ตั้งจำนวนรอบการเทรน (epochs)\n",
    "epoch = 100\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) สร้างโมเดล GAT และเตรียมฟังก์ชัน Loss + Optimizer\n",
    "# ------------------------------------------------------------\n",
    "# สร้างโมเดล GAT โดยกำหนดพารามิเตอร์:\n",
    "# - in_channels: จำนวนฟีเจอร์ของโหนด (data.num_features)\n",
    "# - hidden_channels: จำนวนหน่วยในเลเยอร์ซ่อน\n",
    "# - out_channels: ขนาดเอาต์พุต (1 สำหรับ binary classification)\n",
    "# - heads: จำนวน attention heads\n",
    "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
    "\n",
    "# ย้ายโมเดลไปยังอุปกรณ์ประมวลผล (GPU/CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# ฟังก์ชัน Loss ที่ใช้วัดข้อผิดพลาด (Binary Cross Entropy)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizer ที่ใช้ปรับค่าน้ำหนัก (ใช้ SGD แบบ learning rate คงที่)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) แบ่งข้อมูล Train / Validation / Test ด้วย RandomNodeSplit\n",
    "# ------------------------------------------------------------\n",
    "# - split='train_rest' หมายถึง train 80% + val 10% + test 10% (โดยประมาณ)\n",
    "# - num_val=0.1 คือสัดส่วน validation = 10%\n",
    "# - num_test=0 คือไม่มี test set แยกออกมา (ใช้ train/val เท่านั้น)\n",
    "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "\n",
    "# ใช้การ split กับข้อมูลกราฟ\n",
    "data = split(data)\n",
    "\n",
    "# ย้ายข้อมูลกราฟทั้งหมดไปยังอุปกรณ์เดียวกับโมเดล\n",
    "data = data.to(device)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) เริ่มกระบวนการเทรนโมเดล (Training Loop)\n",
    "# ------------------------------------------------------------\n",
    "for i in range(epoch):\n",
    "    # ตั้งสถานะโมเดลให้เป็น train mode (เปิดใช้ dropout)\n",
    "    model.train()\n",
    "\n",
    "    # เคลียร์ gradient จากรอบก่อนหน้า\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # ส่งข้อมูลกราฟเข้าโมเดล เพื่อให้โมเดลทำนายผล (prediction)\n",
    "    pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # คำนวณค่า loss เฉพาะโหนดที่อยู่ใน train_mask\n",
    "    # data.y มีขนาด [num_nodes] → ต้อง unsqueeze(1) ให้เป็น [num_nodes, 1]\n",
    "    loss = criterion(pred[data.train_mask], data.y[data.train_mask].unsqueeze(1))\n",
    "\n",
    "    # ทำการย้อนแพร่กระจายค่าความผิดพลาด (backpropagation)\n",
    "    loss.backward()\n",
    "\n",
    "    # ปรับค่าน้ำหนักของโมเดลตาม gradient\n",
    "    optimizer.step()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6) ประเมินผลบน Validation Set ทุก ๆ 10 epoch\n",
    "    # --------------------------------------------------------\n",
    "    if (i + 1) % 10 == 0:\n",
    "        # ตั้งสถานะเป็น eval mode (ปิด dropout)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # ทำการทำนายอีกครั้งโดยไม่คำนวณ gradient\n",
    "            val_pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "            # ดึงผลเฉพาะโหนดที่อยู่ใน validation mask\n",
    "            val_probs = val_pred[data.val_mask]\n",
    "            val_labels = data.y[data.val_mask].unsqueeze(1)\n",
    "\n",
    "            # คำนวณค่า loss บน validation set\n",
    "            val_loss = criterion(val_probs, val_labels)\n",
    "\n",
    "            # แปลงค่าความน่าจะเป็น (>0.5 → 1, <=0.5 → 0)\n",
    "            # แล้วคำนวณ accuracy\n",
    "            val_acc = ((val_probs > 0.5).float() == val_labels).float().mean().item()\n",
    "\n",
    "        # แสดงผลทุก 10 รอบ\n",
    "        print(f\"Epoch: {i + 1:03d}, \"\n",
    "              f\"Loss: {loss.item():.4f}, \"\n",
    "              f\"Val Loss: {val_loss.item():.4f}, \"\n",
    "              f\"Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "Some of the feature engineering of this repo are referenced to below papers, highly recommend to read:\n",
    "1. [Weber, M., Domeniconi, G., Chen, J., Weidele, D. K. I., Bellei, C., Robinson, T., & Leiserson, C. E. (2019). Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. arXiv preprint arXiv:1908.02591.](https://arxiv.org/pdf/1908.02591.pdf)\n",
    "2. [Johannessen, F., & Jullum, M. (2023). Finding Money Launderers Using Heterogeneous Graph Neural Networks. arXiv preprint arXiv:2307.13499.](https://arxiv.org/pdf/2307.13499.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
